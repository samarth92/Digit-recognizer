{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    " \n",
    "train_input = ['{0:020b}'.format(i) for i in range(2**20)]\n",
    "shuffle(train_input)\n",
    "train_input = [map(int,i) for i in train_input]\n",
    "ti  = []\n",
    "for i in train_input:\n",
    "    temp_list = []\n",
    "    for j in i:\n",
    "            temp_list.append([j])\n",
    "    ti.append(np.array(temp_list))\n",
    "train_input = ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_output = []\n",
    " \n",
    "for i in train_input:\n",
    "    count = 0\n",
    "    for j in i:\n",
    "        if j[0] == 1:\n",
    "            count+=1\n",
    "    temp_list = ([0]*21)\n",
    "    temp_list[count]=1\n",
    "    train_output.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generating test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = 10000\n",
    "test_input = train_input[NUM_EXAMPLES:]\n",
    "test_output = train_output[NUM_EXAMPLES:] #everything beyond 10,000\n",
    " \n",
    "train_input = train_input[:NUM_EXAMPLES]\n",
    "train_output = train_output[:NUM_EXAMPLES] #till 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = tf.placeholder(tf.float32,[None,20,1])\n",
    "target = tf.placeholder(tf.float32,[None,21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_hidden=24\n",
    "cell = tf.nn.rnn_cell.LSTMCell(num_hidden,state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val,state =tf.nn.dynamic_rnn(cell,data,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = tf.transpose(val,[1,0,2])\n",
    "last=tf.gather(val,int(val.get_shape()[0])-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([num_hidden, int(target.get_shape()[1])]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[target.get_shape()[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.nn.softmax(tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(target * tf.log(tf.clip_by_value(prediction,1e-10,1.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "minimize = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mistakes = tf.not_equal(tf.argmax(target, 1), tf.argmax(prediction, 1))\n",
    "error = tf.reduce_mean(tf.cast(mistakes, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch -  0\n",
      "Epoch -  1\n",
      "Epoch -  2\n",
      "Epoch -  3\n",
      "Epoch -  4\n",
      "Epoch -  5\n",
      "Epoch -  6\n",
      "Epoch -  7\n",
      "Epoch -  8\n",
      "Epoch -  9\n",
      "Epoch -  10\n",
      "Epoch -  11\n",
      "Epoch -  12\n",
      "Epoch -  13\n",
      "Epoch -  14\n",
      "Epoch -  15\n",
      "Epoch -  16\n",
      "Epoch -  17\n",
      "Epoch -  18\n",
      "Epoch -  19\n",
      "Epoch -  20\n",
      "Epoch -  21\n",
      "Epoch -  22\n",
      "Epoch -  23\n",
      "Epoch -  24\n",
      "Epoch -  25\n",
      "Epoch -  26\n",
      "Epoch -  27\n",
      "Epoch -  28\n",
      "Epoch -  29\n",
      "Epoch -  30\n",
      "Epoch -  31\n",
      "Epoch -  32\n",
      "Epoch -  33\n",
      "Epoch -  34\n",
      "Epoch -  35\n",
      "Epoch -  36\n",
      "Epoch -  37\n",
      "Epoch -  38\n",
      "Epoch -  39\n",
      "Epoch -  40\n",
      "Epoch -  41\n",
      "Epoch -  42\n",
      "Epoch -  43\n",
      "Epoch -  44\n",
      "Epoch -  45\n",
      "Epoch -  46\n",
      "Epoch -  47\n",
      "Epoch -  48\n",
      "Epoch -  49\n",
      "Epoch -  50\n",
      "Epoch -  51\n",
      "Epoch -  52\n",
      "Epoch -  53\n",
      "Epoch -  54\n",
      "Epoch -  55\n",
      "Epoch -  56\n",
      "Epoch -  57\n",
      "Epoch -  58\n",
      "Epoch -  59\n",
      "Epoch -  60\n",
      "Epoch -  61\n",
      "Epoch -  62\n",
      "Epoch -  63\n",
      "Epoch -  64\n",
      "Epoch -  65\n",
      "Epoch -  66\n",
      "Epoch -  67\n",
      "Epoch -  68\n",
      "Epoch -  69\n",
      "Epoch -  70\n",
      "Epoch -  71\n",
      "Epoch -  72\n",
      "Epoch -  73\n",
      "Epoch -  74\n",
      "Epoch -  75\n",
      "Epoch -  76\n",
      "Epoch -  77\n",
      "Epoch -  78\n",
      "Epoch -  79\n",
      "Epoch -  80\n",
      "Epoch -  81\n",
      "Epoch -  82\n",
      "Epoch -  83\n",
      "Epoch -  84\n",
      "Epoch -  85\n",
      "Epoch -  86\n",
      "Epoch -  87\n",
      "Epoch -  88\n",
      "Epoch -  89\n",
      "Epoch -  90\n",
      "Epoch -  91\n",
      "Epoch -  92\n",
      "Epoch -  93\n",
      "Epoch -  94\n",
      "Epoch -  95\n",
      "Epoch -  96\n",
      "Epoch -  97\n",
      "Epoch -  98\n",
      "Epoch -  99\n",
      "Epoch -  100\n",
      "Epoch -  101\n",
      "Epoch -  102\n",
      "Epoch -  103\n",
      "Epoch -  104\n",
      "Epoch -  105\n",
      "Epoch -  106\n",
      "Epoch -  107\n",
      "Epoch -  108\n",
      "Epoch -  109\n",
      "Epoch -  110\n",
      "Epoch -  111\n",
      "Epoch -  112\n",
      "Epoch -  113\n",
      "Epoch -  114\n",
      "Epoch -  115\n",
      "Epoch -  116\n",
      "Epoch -  117\n",
      "Epoch -  118\n",
      "Epoch -  119\n",
      "Epoch -  120\n",
      "Epoch -  121\n",
      "Epoch -  122\n",
      "Epoch -  123\n",
      "Epoch -  124\n",
      "Epoch -  125\n",
      "Epoch -  126\n",
      "Epoch -  127\n",
      "Epoch -  128\n",
      "Epoch -  129\n",
      "Epoch -  130\n",
      "Epoch -  131\n",
      "Epoch -  132\n",
      "Epoch -  133\n",
      "Epoch -  134\n",
      "Epoch -  135\n",
      "Epoch -  136\n",
      "Epoch -  137\n",
      "Epoch -  138\n",
      "Epoch -  139\n",
      "Epoch -  140\n",
      "Epoch -  141\n",
      "Epoch -  142\n",
      "Epoch -  143\n",
      "Epoch -  144\n",
      "Epoch -  145\n",
      "Epoch -  146\n",
      "Epoch -  147\n",
      "Epoch -  148\n",
      "Epoch -  149\n",
      "Epoch -  150\n",
      "Epoch -  151\n",
      "Epoch -  152\n",
      "Epoch -  153\n",
      "Epoch -  154\n",
      "Epoch -  155\n",
      "Epoch -  156\n",
      "Epoch -  157\n",
      "Epoch -  158\n",
      "Epoch -  159\n",
      "Epoch -  160\n",
      "Epoch -  161\n",
      "Epoch -  162\n",
      "Epoch -  163\n",
      "Epoch -  164\n",
      "Epoch -  165\n",
      "Epoch -  166\n",
      "Epoch -  167\n",
      "Epoch -  168\n",
      "Epoch -  169\n",
      "Epoch -  170\n",
      "Epoch -  171\n",
      "Epoch -  172\n",
      "Epoch -  173\n",
      "Epoch -  174\n",
      "Epoch -  175\n",
      "Epoch -  176\n",
      "Epoch -  177\n",
      "Epoch -  178\n",
      "Epoch -  179\n",
      "Epoch -  180\n",
      "Epoch -  181\n",
      "Epoch -  182\n",
      "Epoch -  183\n",
      "Epoch -  184\n",
      "Epoch -  185\n",
      "Epoch -  186\n",
      "Epoch -  187\n",
      "Epoch -  188\n",
      "Epoch -  189\n",
      "Epoch -  190\n",
      "Epoch -  191\n",
      "Epoch -  192\n",
      "Epoch -  193\n",
      "Epoch -  194\n",
      "Epoch -  195\n",
      "Epoch -  196\n",
      "Epoch -  197\n",
      "Epoch -  198\n",
      "Epoch -  199\n",
      "Epoch -  200\n",
      "Epoch -  201\n",
      "Epoch -  202\n",
      "Epoch -  203\n",
      "Epoch -  204\n",
      "Epoch -  205\n",
      "Epoch -  206\n",
      "Epoch -  207\n",
      "Epoch -  208\n",
      "Epoch -  209\n",
      "Epoch -  210\n",
      "Epoch -  211\n",
      "Epoch -  212\n",
      "Epoch -  213\n",
      "Epoch -  214\n",
      "Epoch -  215\n",
      "Epoch -  216\n",
      "Epoch -  217\n",
      "Epoch -  218\n",
      "Epoch -  219\n",
      "Epoch -  220\n",
      "Epoch -  221\n",
      "Epoch -  222\n",
      "Epoch -  223\n",
      "Epoch -  224\n",
      "Epoch -  225\n",
      "Epoch -  226\n",
      "Epoch -  227\n",
      "Epoch -  228\n",
      "Epoch -  229\n",
      "Epoch -  230\n",
      "Epoch -  231\n",
      "Epoch -  232\n",
      "Epoch -  233\n",
      "Epoch -  234\n",
      "Epoch -  235\n",
      "Epoch -  236\n",
      "Epoch -  237\n",
      "Epoch -  238\n",
      "Epoch -  239\n",
      "Epoch -  240\n",
      "Epoch -  241\n",
      "Epoch -  242\n",
      "Epoch -  243\n",
      "Epoch -  244\n",
      "Epoch -  245\n",
      "Epoch -  246\n",
      "Epoch -  247\n",
      "Epoch -  248\n",
      "Epoch -  249\n",
      "Epoch -  250\n",
      "Epoch -  251\n",
      "Epoch -  252\n",
      "Epoch -  253\n",
      "Epoch -  254\n",
      "Epoch -  255\n",
      "Epoch -  256\n",
      "Epoch -  257\n",
      "Epoch -  258\n",
      "Epoch -  259\n",
      "Epoch -  260\n",
      "Epoch -  261\n",
      "Epoch -  262\n",
      "Epoch -  263\n",
      "Epoch -  264\n",
      "Epoch -  265\n",
      "Epoch -  266\n",
      "Epoch -  267\n",
      "Epoch -  268\n",
      "Epoch -  269\n",
      "Epoch -  270\n",
      "Epoch -  271\n",
      "Epoch -  272\n",
      "Epoch -  273\n",
      "Epoch -  274\n",
      "Epoch -  275\n",
      "Epoch -  276\n",
      "Epoch -  277\n",
      "Epoch -  278\n",
      "Epoch -  279\n",
      "Epoch -  280\n",
      "Epoch -  281\n",
      "Epoch -  282\n",
      "Epoch -  283\n",
      "Epoch -  284\n",
      "Epoch -  285\n",
      "Epoch -  286\n",
      "Epoch -  287\n",
      "Epoch -  288\n",
      "Epoch -  289\n",
      "Epoch -  290\n",
      "Epoch -  291\n",
      "Epoch -  292\n",
      "Epoch -  293\n",
      "Epoch -  294\n",
      "Epoch -  295\n",
      "Epoch -  296\n",
      "Epoch -  297\n",
      "Epoch -  298\n",
      "Epoch -  299\n",
      "Epoch 300 error 0.1%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "no_of_batches = int(len(train_input)/batch_size)\n",
    "epoch = 300\n",
    "for i in range(epoch):\n",
    "    ptr = 0\n",
    "    for j in range(no_of_batches):\n",
    "        inp, out = train_input[ptr:ptr+batch_size], train_output[ptr:ptr+batch_size]\n",
    "        ptr+=batch_size\n",
    "        sess.run(minimize,{data: inp, target: out})\n",
    "    print (\"Epoch - \",str(i))\n",
    "incorrect = sess.run(error,{data: test_input, target: test_output})\n",
    "print('Epoch {:2d} error {:3.1f}%'.format(i + 1, 100 * incorrect))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-319652e530eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print( sess.run(model.prediction,{data: [[[1],[0],[0],[1],[1],[0],[1],[1],[1],[0],[1],[0],[0],[1],[1],[0],[1],[1],[1],[0]]]}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
